
@article{landa_meshworks_nodate,
	title = {{MESHWORKS}, {HIERARCHIES} {AND} {INTERFACES}},
	pages = {6},
	author = {Landa, Manuel De},
	langid = {english},
	file = {Landa - MESHWORKS, HIERARCHIES AND INTERFACES.pdf:C\:\\Users\\Barrett\\Zotero\\storage\\64CHLM9R\\Landa - MESHWORKS, HIERARCHIES AND INTERFACES.pdf:application/pdf}
}

@article{compton_generative_nodate,
	title = {A Generative Framework of Generativity},
	abstract = {Several frameworks exist to describe how procedural content can be understood, or how it can be used in games. In this paper, we present a framework that considers generativity as a pipeline of successive data transformations, with each transformation either generating, transforming, or pruning away information. This framework has been iterated through repeated engagement and education interactions with the game development and generative art communities. In its most recent reﬁnement, it has been physically instantiated into a deck of cards, which can be used to analyze existing examples of generativity or design new generative systems. This Generative Framework of Generativity aims to constructively deﬁne the design space of generative pipelines.},
	pages = {8},
	author = {Compton, Kate and Mateas, Michael},
	langid = {english},
	file = {Compton and Mateas - A Generative Framework of Generativity.pdf:C\:\\Users\\Barrett\\Zotero\\storage\\Y3GFBDUJ\\Compton and Mateas - A Generative Framework of Generativity.pdf:application/pdf;Compton and Mateas - A Generative Framework of Generativity.pdf:C\:\\Users\\Barrett\\Zotero\\storage\\4BATCGMN\\Compton and Mateas - A Generative Framework of Generativity.pdf:application/pdf}
}

@online{noauthor_weapons_nodate,
	title = {Weapons of Math Destruction by Cathy O'Neil {\textbar} {PenguinRandomHouse}.com: Books},
	url = {https://www.penguinrandomhouse.com/books/241363/weapons-of-math-destruction-by-cathy-oneil/9780553418835},
	shorttitle = {Weapons of Math Destruction by Cathy O'Neil {\textbar} {PenguinRandomHouse}.com},
	abstract = {Longlisted for the National Book Award New York Times Bestseller  A former Wall Street quant sounds an alarm on the mathematical models that pervade modern life — and threaten to rip apart our...},
	titleaddon = {{PenguinRandomhouse}.com},
	urldate = {2019-06-12},
	langid = {american},
	file = {Snapshot:C\:\\Users\\Barrett\\Zotero\\storage\\KA9GN8L3\\9780553418835.html:text/html}
}

@online{hart_parable_nodate,
	title = {Parable of the Polygons},
	url = {http://ncase.me/polygons},
	abstract = {A playable post on how harmless choices can make a harmful world.},
	titleaddon = {Parable of the Polygons},
	author = {Hart, Vi and Case, Nicky},
	urldate = {2019-06-12},
	file = {Snapshot:C\:\\Users\\Barrett\\Zotero\\storage\\KT8KEW3H\\polygons.html:text/html}
}

@incollection{gold_trending:_2012,
	title = {Trending: The Promises and the Challenges of Big Social Data},
	isbn = {978-0-8166-7794-8},
	url = {http://minnesota.universitypressscholarship.com/view/10.5749/minnesota/9780816677948.001.0001/upso-9780816677948-chapter-47},
	shorttitle = {Trending},
	pages = {460--475},
	booktitle = {Debates in the Digital Humanities},
	publisher = {University of Minnesota Press},
	author = {Manovich, Lev},
	editor = {Gold, Matthew K.},
	urldate = {2019-06-12},
	date = {2012-01-01},
	langid = {english},
	doi = {10.5749/minnesota/9780816677948.003.0047},
	file = {Manovich - 2012 - Trending The Promises and the Challenges of Big S.pdf:C\:\\Users\\Barrett\\Zotero\\storage\\V29GCQ9E\\Manovich - 2012 - Trending The Promises and the Challenges of Big S.pdf:application/pdf}
}

@inproceedings{compton_tracery:_2015,
	title = {Tracery: An Author-Focused Generative Text Tool},
	isbn = {978-3-319-27036-4},
	series = {Lecture Notes in Computer Science},
	shorttitle = {Tracery},
	abstract = {New communities of generative text practitioners are flourishing in novel expressive mediums like Twitterbots and Twine as well as the existing practices of Interactive Fiction. However, there are not yet reusable and extensible generative text tools that work for the needs of these communities. Tracery is an author-focused generative text tool, intended to be used by novice and expert authors, and designed to support generative text creation in these growing communities, and future ones. We identify the design considerations necessary to serve these new generative text authors, like data portability, modular design, and additive authoring, and illustrate how these considerations informed the design of the Tracery language. We also present illustrative case studies of existing projects that use Tracery as part of the art creation process.},
	pages = {154--161},
	booktitle = {Interactive Storytelling},
	publisher = {Springer International Publishing},
	author = {Compton, Kate and Kybartas, Ben and Mateas, Michael},
	editor = {Schoenau-Fog, Henrik and Bruni, Luis Emilio and Louchart, Sandy and Baceviciute, Sarune},
	date = {2015},
	langid = {english},
	keywords = {Expansion Rule, Formal Grammar, Generative Text, Interruption Junction, Narrative Generation},
	file = {Springer Full Text PDF:C\:\\Users\\Barrett\\Zotero\\storage\\EV6VSZZH\\Compton et al. - 2015 - Tracery An Author-Focused Generative Text Tool.pdf:application/pdf}
}

@article{radford_language_nodate,
	title = {Language Models are Unsupervised Multitask Learners},
	abstract = {Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspeciﬁc datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called {WebText}. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the {CoQA} dataset - matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, {GPT}-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underﬁts {WebText}. Samples from the model reﬂect these improvements and contain coherent paragraphs of text. These ﬁndings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.},
	pages = {24},
	author = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
	langid = {english},
	file = {Radford et al. - Language Models are Unsupervised Multitask Learner.pdf:C\:\\Users\\Barrett\\Zotero\\storage\\UTJELLK4\\Radford et al. - Language Models are Unsupervised Multitask Learner.pdf:application/pdf}
}

@online{noauthor_bruises_nodate,
	title = {{BRUISES} - The Data We Don't See},
	url = {http://giorgialupi.com/bruises-the-data-we-dont-see},
	titleaddon = {giorgialupi},
	urldate = {2019-06-12},
	langid = {american},
	file = {Snapshot:C\:\\Users\\Barrett\\Zotero\\storage\\37I3SW79\\bruises-the-data-we-dont-see.html:text/html}
}

@article{turchin_arise_2008,
	title = {Arise 'cliodynamics'},
	volume = {454},
	rights = {2008 Nature Publishing Group},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/454034a},
	doi = {10.1038/454034a},
	abstract = {If we are to learn how to develop a healthy society, we must transform history into an analytical, predictive science, argues Peter Turchin. He has identified intriguing patterns across vastly different times and places.},
	pages = {34--35},
	journaltitle = {Nature},
	author = {Turchin, Peter},
	urldate = {2019-06-12},
	date = {2008-07-02},
	langid = {english},
	file = {Full Text PDF:C\:\\Users\\Barrett\\Zotero\\storage\\XWFK9YLW\\Turchin - 2008 - Arise 'cliodynamics'.pdf:application/pdf;Snapshot:C\:\\Users\\Barrett\\Zotero\\storage\\LLG25ZGT\\454034a.html:text/html}
}

@book{gottman_mathematics_2005,
	title = {The Mathematics of Marriage: Dynamic Nonlinear Models},
	isbn = {978-0-262-25045-0},
	shorttitle = {The Mathematics of Marriage},
	abstract = {Divorce rates are at an all-time high. But without a theoretical understanding of the processes related to marital stability and dissolution, it is difficult to design and evaluate new marriage interventions. The Mathematics of Marriage provides the foundation for a scientific theory of marital relations. The book does not rely on metaphors, but develops and applies a mathematical model using difference equations. The work is the fulfillment of the goal to build a mathematical framework for the general system theory of families first suggested by Ludwig Von Bertalanffy in the 1960s.The book also presents a complete introduction to the mathematics involved in theory building and testing, and details the development of experiments and models. In one "marriage experiment," for example, the authors explored the effects of lowering or raising a couple's heart rates. Armed with their mathematical model, they were able to do real experiments to determine which processes were affected by their interventions. Applying ideas such as phase space, null clines, influence functions, inertia, and uninfluenced and influenced stable steady states (attractors), the authors show how other researchers can use the methods to weigh their own data with positive and negative weights. While the focus is on modeling marriage, the techniques can be applied to other types of psychological phenomena as well. . Applying ideas such as phase space, null clines, influence functions, inertia, and uninfluenced and influenced stable steady states (attractors), the authors show how other researchers can use the methods to weigh their own data with positive and negative weights. While the focus is on modeling marriage, the techniques can be applied to other types of psychological phenomena as well.},
	pagetotal = {428},
	publisher = {{MIT} Press},
	author = {Gottman, John Mordechai},
	date = {2005-01-14},
	langid = {english},
	note = {Google-Books-{ID}: {efEuNZXBWrYC}},
	keywords = {Psychology / General, Social Science / Sociology / Marriage \& Family}
}

@online{noauthor_ucsc_nodate,
	title = {{UCSC} Creative Coding},
	url = {https://creativecoding.soe.ucsc.edu/courses/cmpm202/schedule.php},
	urldate = {2019-06-11},
	file = {UCSC Creative Coding:C\:\\Users\\Barrett\\Zotero\\storage\\VZYRK4QA\\schedule.html:text/html}
}

@video{!!con_!!con_nodate,
	title = {!!Con West 2019 - Max Kreminski: Making blackout poetry with computers!},
	url = {https://www.youtube.com/watch?v=klO7XBFUIj8},
	shorttitle = {!!Con West 2019 - Max Kreminski},
	author = {{!!Con}},
	urldate = {2019-06-10}
}

@online{noauthor_tracery_nodate,
	title = {Tracery - anchor},
	url = {http://www.galaxykate.com/generominos/},
	urldate = {2019-06-10},
	file = {Tracery - anchor:C\:\\Users\\Barrett\\Zotero\\storage\\9KT2UL6G\\generominos.html:text/html}
}

@online{ferrini_deep_2019,
	title = {Deep Learning and Doughnuts},
	url = {https://towardsdatascience.com/deep-learning-and-doughnuts-c2f0f7b7c598},
	abstract = {Manifold learning},
	titleaddon = {Towards Data Science},
	author = {Ferrini, Mattia},
	urldate = {2019-06-10},
	date = {2019-03-19},
	file = {Snapshot:C\:\\Users\\Barrett\\Zotero\\storage\\UMMD2XIM\\deep-learning-and-doughnuts-c2f0f7b7c598.html:text/html}
}

@online{noauthor_neural_nodate,
	title = {Neural Networks, Manifolds, and Topology -- colah's blog},
	url = {https://colah.github.io/posts/2014-03-NN-Manifolds-Topology/},
	urldate = {2019-06-10}
}

@video{confreaks_!!con_nodate,
	title = {!!Con 2016 - Lossy text compression, for some reason?!  By Allison Parrish},
	url = {https://www.youtube.com/watch?v=meovx9OqWJc},
	shorttitle = {!!Con 2016 - Lossy text compression, for some reason?},
	abstract = {Word embeddings are numerical representations of word meanings in a continuous high-dimensional space. Over the course of 2016, I presented and performed poetry produced through signal processing procedures applied to word embeddings, manipulated expressively in real-time. This research was first supported during a research residence at {DBRS} Innovation Lab, which resulted in a demo app and a comprehensive write-up by Lab staff members. I gave a talk at Alt-{AI} on some of the relevant techniques and my 2016 !!Con talk also touched on my research in this area. With the latest version of the live interface, I performed live creative text synthesis at We Have Always Been Digital, a performance event presented by the Electronic Literature Organization at the Kitchen (curated by Illya Szilak).},
	author = {{Confreaks}},
	urldate = {2019-06-10}
}